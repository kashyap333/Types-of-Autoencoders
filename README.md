# Types-of-Autoencoders :fire: :zap:

Autoencoders are a type of neural network which generates an “n-layer” coding of the given input and attempts to reconstruct the input using the code generated. This Neural Network architecture is divided into the encoder structure, the decoder structure, and the latent space, also known as the “bottleneck”. To learn the data representations of the input, the network is trained using Unsupervised data. These compressed, data representations go through a decoding process wherein which the input is reconstructed. An autoencoder is a regression task that models an identity function.

### ***AutoEncoders are used to find the most important features***

> Read more about various autoencoders [here](https://iq.opengenus.org/types-of-autoencoder/)

Here you can find the following type of Autoencoder ( The marked ones are the ones which are completed, will upload the others soon..)
- [x] Undercomplete autoencoders
- [x] Sparse autoencoders
- [x] Denoising Autoencoder
- [ ] Contractive Autoencoder
- [ ] Variational Autoencoder
- [ ] Stacked Denoising Autoencoders
- [ ] Deep Autoencoders

A Deeper explanation can be found inside the respective .ipynb or .py files


